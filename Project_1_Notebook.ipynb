{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENDG 310 Project #1\n",
    "\n",
    "## Loading and Visualizing Data\n",
    " \n",
    "Below is my code for loading arranging my data in a format that will be easy for me to work with. I have downloaded several sets of data, the first is daily data from Canada Border Services Agency (CBSA) which lists how many people have entered the coutry every day for the past five year (2018-2023). The next sets of data are all data on yearly wages, one for each year from 2018-2022. I will load the Canada Border Services code and read it, and I will combine the five csv file for wages into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('c:\\\\Users\\\\Isabel Conklin\\\\Documents\\\\ENDG 310\\\\Github23-24\\\\ENDG310-Project-1-F2023\\\\Functions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Column:  0\n",
      "df:  [[Timestamp('2018-01-01 00:00:00') '2060 - Moncton' 'Atlantic Region'\n",
      "  'Air' 119]\n",
      " [Timestamp('2018-01-01 00:00:00') '2110 - St. Stephen - Traffic'\n",
      "  'Atlantic Region' 'Land' 843]\n",
      " [Timestamp('2018-01-01 00:00:00') '2114 - St. Stephen - 3rd Bridge'\n",
      "  'Atlantic Region' 'Land' 364]\n",
      " ...\n",
      " [Timestamp('2018-12-31 00:00:00') 'TRC' 'Prairie Region' 'Land' 127]\n",
      " [Timestamp('2018-12-31 00:00:00') 'TRC' 'Quebec Region' 'Air' 26]\n",
      " [Timestamp('2018-12-31 00:00:00') 'TRC' 'Southern Ontario Region' 'Air'\n",
      "  6]]\n",
      "df[date_column]:  [Timestamp('2018-01-01 00:00:00') '2060 - Moncton' 'Atlantic Region' 'Air'\n",
      " 119]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Unknown string format: 2060 - Moncton",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2211\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2210\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2211\u001b[0m     values, tz_parsed \u001b[39m=\u001b[39m conversion\u001b[39m.\u001b[39;49mdatetime_to_datetime64(data\u001b[39m.\u001b[39;49mravel(\u001b[39m\"\u001b[39;49m\u001b[39mK\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m   2212\u001b[0m     \u001b[39m# If tzaware, these values represent unix timestamps, so we\u001b[39;00m\n\u001b[0;32m   2213\u001b[0m     \u001b[39m#  return them as i8 to distinguish from wall times\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx:360\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Isabel Conklin\\Documents\\ENDG 310\\Github23-24\\ENDG310-Project-1-F2023\\Project_1_Notebook.ipynb Cell 3\u001b[0m line \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Isabel%20Conklin/Documents/ENDG%20310/Github23-24/ENDG310-Project-1-F2023/Project_1_Notebook.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m sorted_data_by_year_and_season \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Isabel%20Conklin/Documents/ENDG%20310/Github23-24/ENDG310-Project-1-F2023/Project_1_Notebook.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m year, year_data \u001b[39min\u001b[39;00m data_by_year\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Isabel%20Conklin/Documents/ENDG%20310/Github23-24/ENDG310-Project-1-F2023/Project_1_Notebook.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     sorted_data \u001b[39m=\u001b[39m seasons_sort(year_data, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Isabel%20Conklin/Documents/ENDG%20310/Github23-24/ENDG310-Project-1-F2023/Project_1_Notebook.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     sorted_data_by_year_and_season[year] \u001b[39m=\u001b[39m sorted_data\n",
      "File \u001b[1;32mc:\\Users\\Isabel Conklin\\Documents\\ENDG 310\\Github23-24\\ENDG310-Project-1-F2023\\Functions\\seasons_sort.py:49\u001b[0m, in \u001b[0;36mseasons_sort\u001b[1;34m(df, date_column)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mdf[date_column]: \u001b[39m\u001b[39m'\u001b[39m, (df[date_column]))\n\u001b[0;32m     48\u001b[0m \u001b[39m#print (pd.to_datetime(df[date_column]))\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m df[date_column] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_datetime(df[date_column])\n\u001b[0;32m     51\u001b[0m \u001b[39m# Extract the month from the date column\u001b[39;00m\n\u001b[0;32m     52\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mMonth\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[date_column]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mmonth\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1076\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1074\u001b[0m         result \u001b[39m=\u001b[39m _convert_and_box_cache(arg, cache_array)\n\u001b[0;32m   1075\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1076\u001b[0m         result \u001b[39m=\u001b[39m convert_listlike(arg, \u001b[39mformat\u001b[39;49m)\n\u001b[0;32m   1077\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1078\u001b[0m     result \u001b[39m=\u001b[39m convert_listlike(np\u001b[39m.\u001b[39marray([arg]), \u001b[39mformat\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:402\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m infer_datetime_format\n\u001b[0;32m    401\u001b[0m utc \u001b[39m=\u001b[39m tz \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mutc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 402\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    403\u001b[0m     arg,\n\u001b[0;32m    404\u001b[0m     dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m    405\u001b[0m     yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m    406\u001b[0m     utc\u001b[39m=\u001b[39;49mutc,\n\u001b[0;32m    407\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    408\u001b[0m     require_iso8601\u001b[39m=\u001b[39;49mrequire_iso8601,\n\u001b[0;32m    409\u001b[0m     allow_object\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    410\u001b[0m )\n\u001b[0;32m    412\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    413\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    414\u001b[0m     \u001b[39m# is in UTC\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     dta \u001b[39m=\u001b[39m DatetimeArray(result, dtype\u001b[39m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2217\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2215\u001b[0m         \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mview(\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m), tz_parsed\n\u001b[0;32m   2216\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m-> 2217\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m   2219\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2220\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2221\u001b[0m     \u001b[39m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2222\u001b[0m     \u001b[39m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[0;32m   2223\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mview(\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m), tz_parsed\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2199\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2197\u001b[0m order: Literal[\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m flags\u001b[39m.\u001b[39mf_contiguous \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2199\u001b[0m     result, tz_parsed \u001b[39m=\u001b[39m tslib\u001b[39m.\u001b[39;49marray_to_datetime(\n\u001b[0;32m   2200\u001b[0m         data\u001b[39m.\u001b[39;49mravel(\u001b[39m\"\u001b[39;49m\u001b[39mK\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   2201\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   2202\u001b[0m         utc\u001b[39m=\u001b[39;49mutc,\n\u001b[0;32m   2203\u001b[0m         dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m   2204\u001b[0m         yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m   2205\u001b[0m         require_iso8601\u001b[39m=\u001b[39;49mrequire_iso8601,\n\u001b[0;32m   2206\u001b[0m         allow_mixed\u001b[39m=\u001b[39;49mallow_mixed,\n\u001b[0;32m   2207\u001b[0m     )\n\u001b[0;32m   2208\u001b[0m     result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mreshape(data\u001b[39m.\u001b[39mshape, order\u001b[39m=\u001b[39morder)\n\u001b[0;32m   2209\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:381\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:613\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:751\u001b[0m, in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:742\u001b[0m, in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:281\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\dateutil\\parser\\_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[39mreturn\u001b[39;00m parser(parserinfo)\u001b[39m.\u001b[39mparse(timestr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1367\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[39mreturn\u001b[39;00m DEFAULTPARSER\u001b[39m.\u001b[39mparse(timestr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\Anaconda\\lib\\site-packages\\dateutil\\parser\\_parser.py:643\u001b[0m, in \u001b[0;36mparser.parse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    640\u001b[0m res, skipped_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse(timestr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    642\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m ParserError(\u001b[39m\"\u001b[39m\u001b[39mUnknown string format: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, timestr)\n\u001b[0;32m    645\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    646\u001b[0m     \u001b[39mraise\u001b[39;00m ParserError(\u001b[39m\"\u001b[39m\u001b[39mString does not contain a date: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, timestr)\n",
      "\u001b[1;31mParserError\u001b[0m: Unknown string format: 2060 - Moncton"
     ]
    }
   ],
   "source": [
    "# CBSA data\n",
    "import pandas as pd\n",
    "from Functions.year_arrays import make_year_arrays\n",
    "from Functions.seasons_sort import seasons_sort\n",
    "\n",
    "\n",
    "# Load CBSA data\n",
    "cbsa = pd.read_csv('Data/traveller_report.csv', encoding= 'ISO-8859-1')\n",
    "\n",
    "# Sort into arrays for each year using make_year_arrays function\n",
    "data_by_year = make_year_arrays('Data/traveller_report.csv', 'Date', ['Date', 'Port of Entry','Region','Mode','Sum of Volume'])\n",
    "\n",
    "# # Sort into seasons for each year array using seasons function\n",
    "# sorted_data_by_year_and_season = {}\n",
    "\n",
    "# for year, year_data in data_by_year.items():\n",
    "#     sorted_data = seasons_sort(year_data, 0)\n",
    "#     sorted_data_by_year_and_season[year] = sorted_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the wages data into a format that is easier to work with\n",
    "from Functions.add_year_column import add_year_column\n",
    "\n",
    "# Adding a year column to each of the csv files using add_year_column function\n",
    "add_year_column('Data/wages_2018.csv', 'Data/wages_2018.csv', 'Year', '2018')\n",
    "add_year_column('Data/wages_2019.csv', 'Data/wages_2019.csv', 'Year', '2019')\n",
    "add_year_column('Data/wages_2020.csv', 'Data/wages_2020.csv', 'Year', '2020')\n",
    "add_year_column('Data/wages_2021.csv', 'Data/wages_2021.csv', 'Year', '2021')\n",
    "add_year_column('Data/wages_2022.csv', 'Data/wages_2022.csv', 'Year', '2022')\n",
    "\n",
    "# In case I accidentally add multiple years columns, can delete using this\n",
    "# df5 = pd.read_csv('Data/wages_2018.csv')\n",
    "# delete_columns = ['Year.1']  # Fix this line\n",
    "# df5.drop(columns=delete_columns, inplace=True)\n",
    "# df5.to_csv('Data/wages_2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the wages data into a format that is easier to work with\n",
    "import pandas as pd\n",
    "\n",
    "# Combine all wages data together into one file\n",
    "# Create a list of file names\n",
    "file_names = ['Data/wages_2018.csv', 'Data/wages_2019.csv', 'Data/wages_2020.csv', 'Data/wages_2021.csv', 'Data/wages_2022.csv']\n",
    "\n",
    "# Initialize an empty list to store individual DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the files and read them into DataFrames, then append to the list\n",
    "for file in file_names:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames vertically\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined files to a new csv file\n",
    "combined_df.to_csv('Data/wages_all.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
